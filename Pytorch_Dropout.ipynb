{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(X, drop_prob):\n",
    "    X = X.float()\n",
    "    keep_prob = 1 - drop_prob\n",
    "\n",
    "    if keep_prob == 0:\n",
    "        return torch.zeros_like(X)\n",
    "    mask = (torch.rand(X.shape)<keep_prob).float()\n",
    "\n",
    "    return mask * X/keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7],\n        [ 8,  9, 10, 11, 12, 13, 14, 15]])\n"
    }
   ],
   "source": [
    "X = torch.arange(16).view(2,8)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_inputs, num_outputs, num_hiddens1, num_hiddens2 = 784, 10, 256, 256\n",
    "\n",
    "W1 = torch.tensor(np.random.normal(0, 0.01, size=(num_inputs, num_hiddens1)), dtype=torch.float, requires_grad=True)\n",
    "b1 = torch.zeros(num_hiddens1, requires_grad=True)\n",
    "W2 = torch.tensor(np.random.normal(0, 0.01, size=(num_hiddens1, num_hiddens2)), dtype=torch.float, requires_grad=True)\n",
    "b2 = torch.zeros(num_hiddens2, requires_grad=True)\n",
    "W3 = torch.tensor(np.random.normal(0, 0.01, size=(num_hiddens2, num_outputs)), dtype=torch.float, requires_grad=True)\n",
    "b3 = torch.zeros(num_outputs, requires_grad=True)\n",
    "\n",
    "params = [W1, b1, W2, b2, W3, b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_prob1, drop_prob2 = 0.2,0.5\n",
    "def net(X, is_training=True):\n",
    "    X = X.view(-1,num_inputs)\n",
    "    H1 = (torch.matmul(X,W1)+b1).relu()\n",
    "    if is_training:\n",
    "        H1 = dropout(H1, drop_prob1)\n",
    "    H2 = (torch.matmul(H1, W2)+b2).relu()\n",
    "    if is_training:\n",
    "        H2 = dropout(H2, drop_prob2)\n",
    "    return torch.matmul(H2, W3)+b3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size,num_workers):\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root='E:\\Training_Sets\\Dropout',\n",
    "                                                    train=True, download=True,\n",
    "                                                    transform=transforms.ToTensor())\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root='E:\\Training_Sets\\Dropout',\n",
    "                                                train=False, download=True,\n",
    "                                                transform=transforms.ToTensor())\n",
    "\n",
    "    train_iter = torch.utils.data.DataLoader(\n",
    "        mnist_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_iter = torch.utils.data.DataLoader(\n",
    "        mnist_test, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    return train_iter,test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for X, y in data_iter:\n",
    "        if isinstance(net, torch.nn.Module):\n",
    "            net.eval() # 评估模式, 这会关闭dropout\n",
    "            acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "            net.train() # 改回训练模式\n",
    "        else: # 自定义的模型\n",
    "            if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
    "                # 将is_training设置成False\n",
    "                acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "            else:\n",
    "                acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "def sgd(params, lr, batch_size):\n",
    "    for param in params:\n",
    "        param.data -= lr * param.grad / batch_size # 注意这里更改param时用的param.data+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_iter, test_iter, num_epochs, net, loss, params, sgd, batch_size, lr):\n",
    "    for epoch in range(num_epochs):\n",
    "        tran_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "        for X, y in train_iter:\n",
    "            y_hat=net(X)\n",
    "\n",
    "            l = loss(y_hat, y).sum()\n",
    "\n",
    "            if params is not None and params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "\n",
    "            l.backward()\n",
    "            sgd(params, lr, batch_size)\n",
    "\n",
    "            train_l_sum = l.item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print(('epoch %d, loss %.9f, train_acc %.3f, test_acc %.3f') % (epoch + 1, train_l_sum/n, train_acc_sum/n, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch 1, loss 0.000010555, train_acc 0.554, test_acc 0.696\nepoch 2, loss 0.000009115, train_acc 0.786, test_acc 0.808\nepoch 3, loss 0.000007967, train_acc 0.822, test_acc 0.827\nepoch 4, loss 0.000004916, train_acc 0.839, test_acc 0.830\nepoch 5, loss 0.000006901, train_acc 0.848, test_acc 0.823\n"
    }
   ],
   "source": [
    "num_epochs,lr=5,100\n",
    "train(train_iter,test_iter,num_epochs,net,loss,params,sgd,batch_size,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<torch.utils.data.dataloader.DataLoader object at 0x000002BBA2BF1BB0>\n"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "metadata": {
    "interpreter": {
     "hash": "54cea3059c761141106f203f3586a6357f5128e74f65359267f2d245ed420a4c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}